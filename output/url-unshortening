<!doctype html>
<html lang="de">
<head>
    <meta charset="utf-8">
    <meta name="language" content="de">
    <title>URL-unshortening</title>
    <meta name="description" content="Auflösen von bit.ly, fb.me und co im großen Stil">
    <meta name="date" content="2017-01-06">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="/assets/styles.css"/>
	<link rel="preload" as="font" type="font/woff2" href="/assets/webfonts/leaguespartan/leaguespartan-bold.woff2">
	<link rel="preload" as="font" type="font/woff2" href="/assets/webfonts/sinanova/sinanova-regular.woff2">

    <link href="/" rel="home start" />
    <link href="/feed/atom" type="application/atom+xml" rel="alternate" title="Atom Feed" />
    <link href="/feed/json" type="application/json" rel="alternate" title="JSON Feed" />
    <link href="/feed/rss" type="application/rss+xml" rel="alternate" title="RSS Feed" />

    <meta property="og:title" content="URL-unshortening" />
    <meta property="og:url" content="https://blog.thomaspuppe.de/url-unshortening" />
    <meta property="og:type" content="article" />
    <meta property="og:article:published_time" content="2017-01-06" />
    <meta property="og:article:author" content="Thomas Puppe" />
</head>
<body>
    <header>
        <p><a href="https://blog.thomaspuppe.de/" rel="home start">Blog von Thomas Puppe, Web Developer.</a></p>
    </header>
    <article class="post">

        <div class="post__meta">
            <span class="post__category">#Webentwicklung</span>
            <time datetime="2017-01-06">06. Januar 2017</time>
        </div>

        <h1 class="post__title">URL-unshortening</h1>

        <p>Für ein aktuelles Feature bei Bundestwitter trage ich gerade zusammen, welche Links von Politikern via Twitter verbreitet wurden. Dabei stellt sich heraus, dass mehr als 20% der geposteten Links sogenannte Shortlinks sind. Also nicht nur die Kürzung von Twitter selbst via <code>t.co</code> (deren echte URLs werden über die APIs mitgeliefert), sondern es werden schon Short-URLs beim Schreiben der Tweets eingegeben.</p>
<p>In Zahlen drückt sich das so aus (bei insgesamt 48.000 Links):</p>
<ul>
<li>6404 &times; fb.me</li>
<li>1506 &times; bit.ly</li>
<li>1072 &times; ow.ly</li>
<li>199 &times; tinyurl.com</li>
<li>187 &times; goo.gl</li>
<li>138 &times; ift.tt</li>
</ul>
<p>Diese URLs möchte ich nun also auflösen. Im Internet findet man darüber <a href="http://security.thejoshmeister.com/2009/04/how-to-preview-shortened-urls-tinyurl.html">Artikel</a>, <a href="http://www.toolsvoid.com/unshorten-url">einige</a> <a href="https://www.unshorten.it/">verschiedene</a> <a href="http://checkshorturl.com/">Dienste </a> und <a href="https://github.com/quark-zju/unshorten">diverse</a> <a href="https://github.com/mathiasbynens/node-unshorten">Scripte</a>, <a href="https://github.com/nodeca/url-unshort">Bibliotheken</a> und <a href="https://gist.github.com/zhasm/986361">Snippets</a> bei GitHub.</p>
<h1 id="eigentlich-ist-es-viel-einfacher">Eigentlich ist es viel einfacher!</h1>
<p>Es stellt sich heraus, dass <em>im Prinzip</em> ein Curl-Aufruf ausreicht. Alle genannten Dienste antworten mit einem HTTP Status 301 und dem Location-Header. <strong>Das Internet ist also doch noch nicht so kaputt wie ich dachte.</strong></p>
<p>In Bash ist das ganz simpel: <code>curl -I http://fb.me/16MEzokwA</code>. Fertig. Wegen der Anbindung an meine Datenbank habe ich die Arbeit mit PHP erledigt, was auch mit Bordmitteln und ein paar Codezeilen funktioniert:</p>
<pre>function get_resp_from_url($url)
{
    $curlConnection = curl_init();
    curl_setopt($curlConnection, CURLOPT_URL, $url);
    curl_setopt($curlConnection, CURLOPT_NOBODY, true);

    if (curl_exec($curlConnection) == false) {
        print 'Curl-Error: ' . curl_error($ch);
        curl_close($curlConnection);
        return false;
    } else {
        $responseInfo = curl_getinfo($curlConnection);
        curl_close($curlConnection);
        return array(
            'status' => $responseInfo['http_code'],
            'location' => $responseInfo['redirect_url']
            );
    }
}</pre>

<p>Einzig Facebook konnte damit nicht abgegrast werden. <code>fb.me</code>-Adressen liefern mir zuverlässig Status 301 bei Abfrage per Bash, und Status 200 mit Facebook-HTML im Body bei der Abfrage per PHP.</p>
<p>Weder Google noch die curl-Referenz für PHP konnten helfen, also musste Python herhalten. Nach dem üblichen erfolglosen Herumirren auf mehreren Wegen (<code>httplib</code> und <code>urllib2</code>) funktioniert es dann auf diese Art:</p>
<pre>import requests
r = requests.get(url, allow_redirects=False)
if r.status_code == 301:
    return r.headers.get('Location')</pre>

<p>Schöne Erkenntnis am Rande: selbst bei hunderten oder tausenden Abfragen im unter-Sekunden-Takt hat keiner der Dienste mit Rate Limiting oder anderer Abweisung reagiert.</p>


    </article>
</body>
</html>
